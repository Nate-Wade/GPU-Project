{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae1a960a",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf8e6abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.parse\n",
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafbb480",
   "metadata": {},
   "source": [
    "## Load and Clean FPS Benchmark json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a05eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load json\n",
    "with open(\"gpus.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "#Flatten and extract nested columns\n",
    "df = pd.json_normalize(data)\n",
    "nested_columns = [col for col in df.columns if \"Settings.\" in col and col.endswith(\".Games\")]\n",
    "\n",
    "#Extract setting and resolution for each game\n",
    "all_games = []\n",
    "for col in nested_columns:\n",
    "    temp = df[[\"Name\", col]].explode(col).dropna().reset_index(drop=True)\n",
    "    games_expanded = pd.json_normalize(temp[col])\n",
    "    \n",
    "    parts = col.split(\".\")\n",
    "    setting = parts[1]        # ultra / high / medium / low\n",
    "    resolution = parts[3]     # resolution\n",
    "    \n",
    "    temp_df = pd.concat([temp[[\"Name\"]], games_expanded], axis=1)\n",
    "    temp_df[\"Setting\"] = setting\n",
    "    temp_df[\"Resolution\"] = resolution\n",
    "    \n",
    "    all_games.append(temp_df)\n",
    "\n",
    "# Combine into one clean DataFrame\n",
    "fps_df = pd.concat(all_games, ignore_index=True)\n",
    "\n",
    "# Keep only desired columns\n",
    "fps_df = fps_df[[\"Name\", \"Game_Name\", \"Min_FPS\", \"Avg_FPS\", \"Setting\", \"Resolution\"]]\n",
    "fps_df = fps_df.sort_values(by=\"Name\").set_index(\"Name\")\n",
    "\n",
    "# Save to CSV\n",
    "fps_df.to_csv(\"data/gpu_fps_only.csv\", index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c08f9e",
   "metadata": {},
   "source": [
    "## Proxy Server Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d651fdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy_host = \"brd.superproxy.io\"\n",
    "proxy_port = 33335\n",
    "proxy_user = \"brd-customer-hl_02785ee1-zone-residential_proxy1\"\n",
    "proxy_pass = \"r2i2po7qyi5s\"\n",
    "\n",
    "country_codes = [\n",
    "    \"ph\",  # Philippines\n",
    "    \"vn\",  # Vietnam\n",
    "    \"eg\",  # Egypt\n",
    "    \"ng\",  # Nigeria\n",
    "    \"ke\",  # Kenya\n",
    "    \"cz\",  # Czech Republic\n",
    "    \"gr\",  # Greece\n",
    "    \"pt\",  # Portugal\n",
    "    \"ro\"   # Romania\n",
    "]\n",
    "\n",
    "PROXY_POOL = [\n",
    "    {\n",
    "        \"http\": f\"http://{proxy_user}-country-{cc}:{proxy_pass}@{proxy_host}:{proxy_port}\",\n",
    "        \"https\": f\"http://{proxy_user}-country-{cc}:{proxy_pass}@{proxy_host}:{proxy_port}\"\n",
    "    }\n",
    "    for cc in country_codes\n",
    "]\n",
    "\n",
    "def get_random_proxy():\n",
    "    return random.choice(PROXY_POOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192e7caf",
   "metadata": {},
   "source": [
    "## Scraping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95780a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpu_page_url(gpu_name, proxy=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Retrieve the TechPowerUp GPU specification page URL for a given GPU name.\n",
    "\n",
    "    This function sends a request to the TechPowerUp GPU database search page\n",
    "    with the provided GPU name, parses the results, and returns the URL of\n",
    "    the first matching GPU's detail page.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gpu_name : str\n",
    "        The name of the GPU to search for (e.g., \"RTX 3080\").\n",
    "    proxy : dict, optional\n",
    "        An optional dictionary of proxy settings to route the request through.\n",
    "        Example: {\"http\": \"http://127.0.0.1:8080\", \"https\": \"http://127.0.0.1:8080\"}\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str or None\n",
    "        A fully-qualified URL to the GPU's detail page on TechPowerUp\n",
    "        (e.g., \"https://www.techpowerup.com/gpu-specs/nvidia-rtx-3080.c3621\"),\n",
    "        or None if no result is found.\n",
    "    \"\"\"\n",
    "    url = f\"https://www.techpowerup.com/gpu-specs/?q={gpu_name}\"\n",
    "\n",
    "    resp = requests.get(url, proxies=proxy, timeout=15, verify=False) if proxy else requests.get(url, timeout=15)\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "    table = soup.find(\"table\", class_=\"items-desktop-table\")\n",
    "    if not table:\n",
    "        return None\n",
    "    first_link = table.find(\"td\").find(\"div\", class_=\"item-name\").find(\"a\")\n",
    "    if first_link:\n",
    "        return \"https://www.techpowerup.com\" + first_link[\"href\"]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f2ca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_gpu_specs(url, gpu_name, proxy=None):\n",
    "        \n",
    "    \"\"\"\n",
    "    Scrape GPU specification details from a TechPowerUp GPU page.\n",
    "\n",
    "    This function retrieves and parses the HTML from a given GPU detail page \n",
    "    on TechPowerUp, extracts specification data from the \"details\" sections,\n",
    "    and returns it as a structured dictionary.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        The full TechPowerUp GPU specification page URL to scrape.\n",
    "        (e.g., \"https://www.techpowerup.com/gpu-specs/nvidia-rtx-3080.c3621\")\n",
    "    gpu_name : str\n",
    "        The name of the GPU being scraped, stored under the 'name' key.\n",
    "    proxy : dict, optional\n",
    "        An optional dictionary of proxy settings for the HTTP request.\n",
    "        Example: {\"http\": \"http://127.0.0.1:8080\", \"https\": \"http://127.0.0.1:8080\"}\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary containing GPU specifications, with:\n",
    "          - \"name\": the GPU name provided in `gpu_name`\n",
    "          - additional key-value pairs for each scraped specification\n",
    "            (keys are normalized: lowercase with spaces replaced by underscores).\n",
    "\n",
    "    \"\"\"\n",
    "    resp = requests.get(url, proxies=proxy, timeout=15, verify=False) if proxy else requests.get(url, timeout=15)\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "    specs = {\"name\": gpu_name}\n",
    "    sections = soup.find(\"div\", class_=\"sectioncontainer\").find_all(\"section\", class_=\"details\")\n",
    "    \n",
    "    for table in sections:\n",
    "        dl_lists = table.find_all(\"dl\")\n",
    "        for dl in dl_lists:\n",
    "            dt_elements = dl.find_all(\"dt\")\n",
    "            dd_elements = dl.find_all(\"dd\")\n",
    "            \n",
    "            if len(dt_elements) != len(dd_elements):\n",
    "                continue\n",
    "            \n",
    "            for dt, dd in zip(dt_elements, dd_elements):\n",
    "                first_value = next(dd.stripped_strings, \"\").strip()\n",
    "                key = dt.text.strip().lower().replace(\" \", \"_\")\n",
    "                specs[key] = first_value\n",
    "                \n",
    "    return specs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460da447",
   "metadata": {},
   "source": [
    "## Initialize Variables for Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5877e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu_specs_build = {}\n",
    "# index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e78a98f",
   "metadata": {},
   "source": [
    "## Scraping Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cc52802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name in gpu_names[index:]:\n",
    "#     # if run_count >= max_runs:\n",
    "#     #     print(\"Reached maximum runs. Exiting loop.\")\n",
    "#     #     break\n",
    "\n",
    "#     proxy = get_random_proxy()   # rotate proxy for each GPU\n",
    "\n",
    "#     url = get_gpu_page_url(name, proxy=proxy)\n",
    "#     if url:\n",
    "#         print(f\"Scraping {name} from {url} via {proxy['http']}\")\n",
    "#         specs = scrape_gpu_specs(url, name, proxy=proxy)\n",
    "#         index += 1\n",
    "\n",
    "#         name_clean = name.replace(\"+\", \" \")\n",
    "#         if name_clean in gpu_specs_build:\n",
    "#             print(f\"Warning: Duplicate entry for {name_clean}\")\n",
    "#         else:\n",
    "#             gpu_specs_build[name_clean] = specs\n",
    "\n",
    "#         # Randomized delay between 5-15 seconds\n",
    "#         sleep_time = random.uniform(5, 15)\n",
    "#         print(f\"Sleeping for {sleep_time:.2f} seconds...\\n\")\n",
    "#         time.sleep(sleep_time)\n",
    "\n",
    "#     else:\n",
    "#         raise Exception(f\"No page found for {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bda08d",
   "metadata": {},
   "source": [
    "## Save data as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a6b383",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn original data into DataFrame \n",
    "#gpu_specs_df_original = pd.DataFrame.from_dict(gpu_specs_build, orient='index')\n",
    "\n",
    "#Save orginal gpu spec data after scraping\n",
    "#gpu_specs_df_original.to_csv(\"data/gpu_specs_original.csv\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
